{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oWm0zXecPh6"
      },
      "source": [
        "# SoftVC Acoustic Model\n",
        "[![Generic badge](https://img.shields.io/badge/GitHub-softVCam-9cf.svg)][github]\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)][notebook]\n",
        "\n",
        "Author: [tarepan]\n",
        "\n",
        "[github]:https://github.com/tarepan/softVC_AM\n",
        "[notebook]:https://colab.research.google.com/github/tarepan/softVC_AM/blob/main/softVC_AM.ipynb\n",
        "[tarepan]:https://github.com/tarepan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFQivUIyZyYi"
      },
      "source": [
        "## Colab Check\n",
        "Check\n",
        "- Google Colaboratory runnning time\n",
        "- GPU type\n",
        "- Python version\n",
        "- CUDA version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cwyMoXOZ7e1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'\n",
        "!head -n 1 /proc/driver/nvidia/gpus/**/information\n",
        "!python --version\n",
        "!pip show torch | sed '2!d'\n",
        "!/usr/local/cuda/bin/nvcc --version | sed '4!d'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K125Ein7VCwM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJCLLQ_8cPiM"
      },
      "source": [
        "Install the package from `tarepan/softVC_AM` public repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ9fU-17Sdxb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Dedicated dependencies install\n",
        "# !pip install \"torch==1.10.0\" -q      # Based on your PyTorch environment\n",
        "# !pip install \"torchaudio==0.10.0\" -q # Based on your PyTorch environment\n",
        "\n",
        "!git clone https://github.com/tarepan/softVC_AM\n",
        "%cd softVC_AM\n",
        "# repository install\n",
        "# !pip uninstall softvcam -y -q\n",
        "# !pip install git+https://github.com/tarepan/softVC_AM -q\n",
        "\n",
        "!pip install git+https://github.com/tarepan/softVC_hubert\n",
        "!pip install git+https://github.com/tarepan/speechcorpusy.git\n",
        "!pip install git+https://github.com/tarepan/extorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptA8A-dhEgqZ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 0: Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import speechcorpusy\n",
        "\n",
        "corpus = speechcorpusy.load_preset(\"LJ\", root=\"/content/gdrive/MyDrive/ML_data\")\n",
        "corpus.get_contents()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!mkdir data_softVC\n",
        "!mkdir data_softVC/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data paths\n",
        "Make list of wav file path relative to data root, under `./data_softVC/train`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import speechcorpusy\n",
        "\n",
        "corpus_id, corpus_name = \"LJ\", \"LJSpeech\"\n",
        "in_wav_dir = Path(f\"tmp/corpuses/{corpus_name}\")\n",
        "corpus = speechcorpusy.load_preset(corpus_id, root=\"/content/gdrive/MyDrive/ML_data\")\n",
        "all_utterances = corpus.get_identities()\n",
        "uttrs_train, uttrs_val = all_utterances[:-20], all_utterances[-20:]\n",
        "\n",
        "with open(\"data_softVC/train/train.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "    for item in uttrs_train:\n",
        "        path_str = str(corpus.get_item_path(item).relative_to(in_wav_dir))\n",
        "        f.write(path_str+\"\\n\")\n",
        "\n",
        "with open(\"data_softVC/train/validation.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "    for item in uttrs_val:\n",
        "        path_str = str(corpus.get_item_path(item).relative_to(in_wav_dir))\n",
        "        f.write(path_str+\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Wave-to-Unit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# For only CPC\n",
        "# !pip install joblib\n",
        "# !wget https://dl.fbaipublicfiles.com/textless_nlp/gslm/cpc/cpc_big_ll6kh_top_ctc.pt\n",
        "# !wget https://dl.fbaipublicfiles.com/textless_nlp/gslm/cpc/km100/km.bin\n",
        "# !pip uninstall \"scikit-learn\" -q -y\n",
        "# !pip install \"scikit-learn==0.24.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# For only vq-wav2vec\n",
        "# !pip install git+https://github.com/tarepan/fairseq.git\n",
        "# !pip install git+https://github.com/tarepan/s3prl.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from hubert.encode import encode_dataset\n",
        "from units.encode import encode_cpc_dataset\n",
        "from units.vqwav2vec import encode_vqwav2vec_dataset\n",
        "\n",
        "\n",
        "#### Change here for your data ###########################\n",
        "soft_disc = \"soft\"\n",
        "# soft_disc = \"discrete\"\n",
        "corpus_name = \"LJSpeech\"\n",
        "in_wav_dir = Path(f\"tmp/corpuses/{corpus_name}\")    # Directory containing .wav input files\n",
        "##########################################################\n",
        "\n",
        "out_unit_dir = Path(f\"./data_softVC/train/{soft_disc}\") # Directory in which new unit series will be saved\n",
        "encode_dataset(soft_disc, in_wav_dir, out_unit_dir, \".wav\")\n",
        "# encode_cpc_dataset(soft_disc, in_wav_dir, out_unit_dir, \".wav\") # CPC discrete\n",
        "# encode_vqwav2vec_dataset(soft_disc, in_wav_dir, out_unit_dir, \".wav\") # VQ-wav2vec discrete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Wave-to-Mel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!python mels.py \"tmp/corpuses/LJSpeech\" \"./data_softVC/train/mels\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKIasW5cTqhl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Launch TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/gdrive/MyDrive/ML_results/softVC_AM\n",
        "\n",
        "!python train.py data_softVC/train /content/gdrive/MyDrive/ML_results/softVC_AM\n",
        "# !python train.py data_softVC/train /content/gdrive/MyDrive/ML_results/softVC_AM --discrete\n",
        "# !python train.py data_softVC/train /content/gdrive/MyDrive/ML_results/softVC_AM --causal\n",
        "# !python train.py data_softVC/train /content/gdrive/MyDrive/ML_results/softVC_AM --discrete --no-upsampling # For CPC\n",
        "# !python train.py data_softVC/train /content/gdrive/MyDrive/ML_results/softVC_AM --resume=/content/gdrive/MyDrive/ML_results/softVC_AM/... # Resume\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxWfhUW4NZmW"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unit-to-Mel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 0: Wave-to-Unit\n",
        "If you do NOT have unit .npy, first generate it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/tarepan/softVC_hubert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from hubert.encode import encode_dataset\n",
        "from units.encode import encode_cpc_dataset\n",
        "\n",
        "#### Change here for your data ###########################\n",
        "soft_disc = \"soft\"\n",
        "# soft_disc = \"discrete\"\n",
        "# soft_disc = \"cpc_discrete\"\n",
        "in_wav_dir = Path(\"./data_softVC/wavs\")    # Directory containing .wav input files\n",
        "out_unit_dir = Path(\"./data_softVC/units\") # Directory in which new unit series will be saved\n",
        "##########################################################\n",
        "\n",
        "out_unit_dir.mkdir(parents=True, exist_ok=True)\n",
        "encode_dataset(soft_disc, in_wav_dir, out_unit_dir, \".wav\")\n",
        "# encode_cpc_dataset(soft_disc, in_wav_dir, out_unit_dir, \".wav\") # CPC discrete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 1: Unit-to-Mel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ3bLy99NZmW",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!python ./generate.py soft     <in-unit-dir> <out-mel-dir>\n",
        "# !python ./generate.py discrete <in-unit-dir> <out-mel-dir>\n",
        "# !python ./generate.py soft \"./data_softVC/units\" \"./data_softVC/mspcs\" # For example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### From Checkpoint\n",
        "1. Make unit series from input waveform\n",
        "2. Apply A2O VC with trained model in the checkpoint\n",
        "3. Make waveform from the mels with pre-trained (LJSpeech-optimized) vocoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "import torch, torchaudio\n",
        "import resampy\n",
        "\n",
        "from acoustic.model import hubert_soft, hubert_discrete\n",
        "\n",
        "\n",
        "# 'Hubert soft' setup\n",
        "soft_disc = \"soft\"\n",
        "# soft_disc = \"discrete\"\n",
        "path_wav_origin = \"<your_audio_data>.wav\"\n",
        "path_am_ckpt = \"<your_AM_checkpoint>.pt\"\n",
        "\n",
        "# Pre-trained models\n",
        "hubert = torch.hub.load(\"bshall/hubert:main\", f\"hubert_{soft_disc}\").cuda()\n",
        "hifigan = torch.hub.load(\"bshall/hifigan:main\", f\"hifigan_hubert_{soft_disc}\").cuda()\n",
        "\n",
        "# Trained AM from the checkpoint\n",
        "acoustic = hubert_soft(pretrained=False) if soft_disc == \"soft\" else hubert_discrete(pretrained=False) if soft_disc == \"discrete\" else \"\"\n",
        "ckpt = torch.load(path_am_ckpt, map_location={\"cuda:0\": f\"cuda:0\"})\n",
        "acoustic.load_state_dict(ckpt[\"acoustic-model\"])\n",
        "acoustic = acoustic.cuda()\n",
        "\n",
        "# Load the source audio\n",
        "i_wave_tmp, sr_source = sf.read(path_wav_origin)\n",
        "path_wav_resampled = \"./resampled.wav\"\n",
        "sf.write(path_wav_resampled, resampy.resample(i_wave_tmp, sr_source, 16000), 16000)\n",
        "i_wave, sr = torchaudio.load(path_wav_resampled)\n",
        "assert sr == 16000\n",
        "i_wave = i_wave.unsqueeze(0).cuda()\n",
        "\n",
        "# Generation\n",
        "with torch.inference_mode():\n",
        "    # Wave-to-Unit\n",
        "    unit_series = hubert.units(i_wave)\n",
        "\n",
        "    # Unit-to-Mel\n",
        "    if soft_disc == \"discrete\":\n",
        "        ## (T, ) -> (1, T) for discrete\n",
        "        unit_series = unit_series.unsqueeze(0)\n",
        "    mspc_series = acoustic.generate(unit_series).transpose(1, 2)\n",
        "\n",
        "    # Mel-to-Wave\n",
        "    o_wave = hifigan(mspc_series)\n",
        "\n",
        "# Display\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "print(\"==========\\nOrigin\")\n",
        "display(Audio(i_wave.squeeze().cpu(), rate=16000))\n",
        "print(\"==========\\nVC\")\n",
        "display(Audio(o_wave.squeeze().cpu(), rate=16000))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "softVC_AM.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
